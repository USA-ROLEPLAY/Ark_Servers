name: ASA Settings Apply

on:
  push:
    branches: [ main ]
    paths:
      - 'ASA/**/GameUserSettings.ini'
      - 'ASA/**/Game.ini'
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write
  actions: write

concurrency:
  group: asa-settings-apply-${{ github.run_id }}
  cancel-in-progress: false

env:
  # Short waits for testing; bump for prod
  WAIT_30M: "30"      # prod: 900
  WAIT_15M: "30"      # prod: 720
  WAIT_3M:  "30"      # prod: 180

  LOG_READY_TIMEOUT:  "600"
  RCON_READY_TIMEOUT: "1200"

jobs:
  build-matrix:
    # Skip if this push is the auto-merge from the compose workflow
    if: ${{ !contains(github.event.head_commit.message, '[auto-gus-sync]') }}
    runs-on: self-hosted
    outputs:
      matrix: ${{ steps.mk-matrix.outputs.matrix }}

    steps:
      - name: Checkout
        uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Compute changed ini files (range-aware)
        id: changed_range
        shell: bash
        run: |
          set -euo pipefail
          BEFORE="${{ github.event.before }}"
          AFTER="${{ github.sha }}"
          if [ -z "${BEFORE}" ] || ! git cat-file -e "${BEFORE}^{commit}" 2>/dev/null; then
            BEFORE="$(git rev-parse HEAD~1)"
          fi
          git --no-pager diff --name-only "${BEFORE}" "${AFTER}" \
            -- 'ASA/**/GameUserSettings.ini' 'ASA/**/Game.ini' > changed.txt || true
          echo "Changed INI files:"
          cat changed.txt || true
          {
            echo "list<<EOF"
            cat changed.txt
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Build matrix from deploy/targets.json
        id: mk-matrix
        uses: actions/github-script@v7
        env:
          CHANGED_LIST: ${{ steps.changed_range.outputs.list }}
        with:
          script: |
            const fs = require('fs');
            const manifest = JSON.parse(fs.readFileSync('deploy/targets.json','utf8'));
            const changed = (process.env.CHANGED_LIST || '')
              .split('\n').map(s => s.trim()).filter(Boolean);

            const picks = [];
            for (const t of manifest.targets) {
              const base = t.work_subdir.replace(/\/+$/,'');
              const gusPath  = `${base}/GameUserSettings.ini`;
              const gamePath = `${base}/Game.ini`;
              const apply_gus  = changed.includes(gusPath);
              const apply_game = changed.includes(gamePath);
              if (apply_gus || apply_game) {
                picks.push({ ...t, apply_gus, apply_game });
              }
            }
            const uniq = Object.values(Object.fromEntries(picks.map(t => [t.id, t])));
            core.info(`Changed files: ${changed.join(', ') || '(none)'}`);
            core.info(`Selected targets: ${uniq.map(t => `${t.id}[gus:${t.apply_gus}/game:${t.apply_game}]`).join(', ') || '(none)'}`);
            core.setOutput('matrix', JSON.stringify(uniq));

  apply:
    needs: build-matrix
    if: ${{ needs.build-matrix.outputs.matrix != '[]' }}
    runs-on: self-hosted
    name: apply (${{ matrix.id }})
    continue-on-error: true
    environment:
      name: host-${{ matrix.ssh_host_secret }}

    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJSON(needs.build-matrix.outputs.matrix) }}

    env:
      SSH_USER: ${{ secrets.ASA_SERVER_SSH_USER }}
      SSH_PORT: ${{ secrets.ASA_SERVER_PORT }}
      HOST: ${{ secrets[matrix.ssh_host_secret] }}
      WORK_DIR: ${{ secrets.WORK_DIR }}

      REPO_SUBDIR: ${{ matrix.work_subdir }}
      CNAME: ${{ matrix.container }}
      LIVE_WIN_DIR: /var/lib/docker/volumes/${{ matrix.volume }}/_data/ShooterGame/Saved/Config/WindowsServer
      APPLY_GUS: ${{ matrix.apply_gus }}
      APPLY_GAME: ${{ matrix.apply_game }}

    steps:
      - name: Mint GitHub App token
        id: app
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.APP_ID2 }}
          private-key: ${{ secrets.APP_PRIVATE_KEY2 }}

      - name: Checkout (for host update)
        uses: actions/checkout@v5
        with:
          fetch-depth: 0
          token: ${{ steps.app.outputs.token }}

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.9.1
        with:
          ssh-private-key: ${{ secrets.ASA_SERVERS_PRIVATE_KEY }}

      # --- Drain & stop (same cadence you use elsewhere) ---
      - name: RCON 30m warning
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" \
            "sudo docker exec '$CNAME' asa-ctrl rcon --exec \"serverchat Server updating settings in 30 minutes\""

      - name: Wait 15m
        run: sleep ${{ env.WAIT_30M }}

      - name: RCON 15m warning
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" \
            "sudo docker exec '$CNAME' asa-ctrl rcon --exec \"serverchat Server updating settings in 15 minutes\""

      - name: Wait 12m
        run: sleep ${{ env.WAIT_15M }}

      - name: RCON 3m warning
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" \
            "sudo docker exec '$CNAME' asa-ctrl rcon --exec \"serverchat Server updating settings in 3 minutes. Final warning!\""

      - name: Wait 3m
        run: sleep ${{ env.WAIT_3M }}

      - name: Saveworld & shutdown announce
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" \
            "sudo docker exec '$CNAME' asa-ctrl rcon --exec \"serverchat Saving world and shutting down for settings update.\" && \
             sudo docker exec '$CNAME' asa-ctrl rcon --exec \"saveworld\""

      - name: Stop container
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" \
            "cd '$WORK_DIR/$REPO_SUBDIR' && sudo docker compose down"

      # --- Update host checkout to main (with GitHub App token) ---
      - name: Update host checkout to origin/main
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" << 'EOF'
          set -euo pipefail
          cd "${{ env.WORK_DIR }}/${{ env.REPO_SUBDIR }}"
          TOKEN='${{ steps.app.outputs.token }}'
          REPO_SLUG='${{ github.repository }}'
          REPO_URL="https://x-access-token:${TOKEN}@github.com/${REPO_SLUG}.git"
          GIT_TERMINAL_PROMPT=0 git fetch --no-tags --prune "$REPO_URL" main
          git reset --hard FETCH_HEAD
          EOF

      # --- Apply changed files only (no privilege/ownership changes) ---
      - name: Inject password & replace files in live volume
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" << 'EOF'
          set -euo pipefail
          cd "${{ env.WORK_DIR }}/${{ env.REPO_SUBDIR }}"
          LIVE="${{ env.LIVE_WIN_DIR }}"

          if [ "${{ env.APPLY_GUS }}" = "true" ]; then
            # Inject admin password placeholder and copy
            sed -i "s/\${SERVER_PASSWORD}/${{ secrets.ASA_ADMIN_SECRET }}/g" GameUserSettings.ini
            sudo rm -f "${LIVE}/GameUserSettings.ini" || true
            sudo cp GameUserSettings.ini "${LIVE}/"
          fi

          if [ "${{ env.APPLY_GAME }}" = "true" ]; then
            sudo rm -f "${LIVE}/Game.ini" || true
            sudo cp Game.ini "${LIVE}/"
          fi
          EOF

      - name: Start container
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" \
            "cd '$WORK_DIR/$REPO_SUBDIR' && sudo docker compose up -d"

      # --- Readiness gates (unchanged) ---
      - name: Wait for startup log ("Starting the ARK...")
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" << 'EOF'
          set -euo pipefail
          CNAME='${{ env.CNAME }}'
          end=$((SECONDS+${{ env.LOG_READY_TIMEOUT }}))
          until sudo docker logs --tail 500 "$CNAME" 2>&1 | grep -q "Starting the ARK: Survival Ascended dedicated server"; do
            if [ $SECONDS -gt $end ]; then
              echo "Timed out waiting for startup log." >&2
              sudo docker logs "$CNAME" --tail 200 >&2 || true
              exit 1
            fi
            sleep 5
          done
          echo "Startup log observed."
          EOF

      - name: Wait for RCON to respond
        run: |
          ssh -o StrictHostKeyChecking=no -p "$SSH_PORT" "$SSH_USER@$HOST" << 'EOF'
          set -euo pipefail
          CNAME='${{ env.CNAME }}'
          end=$((SECONDS+${{ env.RCON_READY_TIMEOUT }}))
          while :; do
            if sudo docker exec "$CNAME" asa-ctrl rcon --exec "listplayers" >/dev/null 2>&1 \
               || sudo docker exec "$CNAME" asa-ctrl rcon --exec "serverchat healthcheck" >/dev/null 2>&1; then
              echo "RCON is responsive."
              break
            fi
            if [ $SECONDS -gt $end ]; then
              echo "Timed out waiting for RCON readiness." >&2
              sudo docker logs "$CNAME" --tail 200 >&2 || true
              exit 1
            fi
            sleep 5
          done
          EOF

  gate-success:
    needs: [apply]
    if: ${{ always() }}             # run even if some shards show failed
    runs-on: ubuntu-latest

    steps:
      - name: Verify only allowed post-step failures and summarize
        uses: actions/github-script@v7
        with:
          github-token: ${{ github.token }}
          script: |
            const run_id = context.runId;

            // Post-step names we agree to tolerate if they "fail"
            const ALLOWED = new Set([
              'Post Setup SSH',
              'Post Checkout (for host update)',
              'Post Checkout'                         // safety catch-all for naming drift
            ]);

            // Pull all jobs/steps from this workflow run
            const { data } = await github.rest.actions.listJobsForWorkflowRun({
              owner: context.repo.owner,
              repo:  context.repo.repo,
              run_id,
              per_page: 100,
              filter: 'latest'
            });

            const rows = [];
            const offenders = [];

            for (const job of data.jobs) {
              // Only look at the apply shards
              if (!job.name || !job.name.startsWith('apply (')) continue;

              const failed = (job.steps || []).filter(s => s.conclusion === 'failure');
              const tolerated = failed.filter(s => ALLOWED.has(s.name));
              const bad = failed.filter(s => !ALLOWED.has(s.name));

              let result = '✅ pass';
              let notes = '';

              if (bad.length) {
                result = '❌ fail';
                notes = `Failed: ${bad.map(s => s.name).join(', ')}`;
                offenders.push(`- ${job.name}: ${bad.map(s => s.name).join(', ')}`);
              } else if (tolerated.length) {
                result = '✅ pass (tolerated flake)';
                notes = `Tolerated: ${tolerated.map(s => s.name).join(', ')}`;
              }

              rows.push(`| ${job.name} | ${result} | ${notes} |`);
            }

            // Nice summary table
            let md = `## ASA Settings Apply — Gate\n\n`;
            if (rows.length) {
              md += `| Target | Result | Notes |\n|---|---|---|\n${rows.join('\n')}\n`;
            } else {
              md += `_No apply shards ran (empty matrix)._`;
            }
            core.summary.addRaw(md).write();

            if (offenders.length) {
              core.setFailed("Non-allowed step failures detected:\n" + offenders.join("\n"));
            } else {
              core.info("Only allowed post-step flakes (if any). Treating workflow as success.");
            }
